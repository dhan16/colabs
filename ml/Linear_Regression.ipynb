{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Q4IRob5ORmtw",
        "pxtPugaq2dqA",
        "mU7GRkOBMxGz",
        "V1M3sCmG5tvQ"
      ],
      "authorship_tag": "ABX9TyOB1HARbJwgCteXUQmPj2+u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhan16/colabs/blob/master/ml/Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression: Theory\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Q4IRob5ORmtw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given data of n observations {**x<sub>i</sub>**, y<sub>i</sub>}<sub>i=1:n</sub> with y<sub>i</sub> a scalar response and **x<sub>i</sub>** a column vector of size p:\n",
        "* y<sub>i</sub> = β<sub>1</sub>x<sub>i1</sub> + ... + β<sub>p</sub>x<sub>ip</sub> + ε<sub>i</sub> = x<sub>i</sub><sup>T</sup>β + ε<sub>i</sub>\n",
        "\n",
        "* or, in vector form: y<sub>i</sub> = **x<sub>i</sub>**<sup>T</sup>**β** + ε<sub>i</sub>\n",
        "\n",
        "* or, stacking the n equations together in matrix notation: **y** = X**β** + **ε**\n",
        "\n",
        "### Ordinary Least Squares Solution\n",
        "Find the coefficients **β** which fit the equations \"best\", **$\\hat{β}$** = arg min S(**β**), where\n",
        "\n",
        "* S(**β**) = ||**y** - X**β**||<sup>2</sup>\n",
        "\n",
        "* The solution is: **$\\hat{β}$** = (X<sup>T</sup>X)<sup>-1</sup> X<sup>T</sup>**y**\n",
        "\n",
        "where (X<sup>T</sup>X)<sup>-1</sup> X<sup>T</sup> is  the Moore–Penrose pseudoinverse matrix of X\n",
        "\n",
        "### Reference\n",
        "* https://en.wikipedia.org/wiki/Ordinary_least_squares#Linear_model\n"
      ],
      "metadata": {
        "id": "51lMvLcRPNMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualisation and data functions"
      ],
      "metadata": {
        "id": "4jK-fKQYKpDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title plot2D() plot3D() show()\n",
        "from matplotlib.font_manager import X11FontDirectories\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot2D(x, y, beta):\n",
        "  plt.plot(x, y, 'o', label='data')\n",
        "  xx = np.linspace(min(x), max(x), 101)\n",
        "  yy = beta[0] + beta[1]*xx\n",
        "  plt.plot(xx, yy, label='least squares fit, $y = a + bx$')\n",
        "  plt.xlabel('x')\n",
        "  plt.ylabel('y')\n",
        "  plt.legend(framealpha=1, shadow=True)\n",
        "  plt.grid(alpha=0.25)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def scale(x, a, b):\n",
        "  '''Scale numpy array to be between min a and max b'''\n",
        "  range = np.amax(x) - np.amin(x)\n",
        "  return x / range * (b - a) + a\n",
        "\n",
        "\n",
        "def plot3D(x, y, beta):\n",
        "  # https://www.kaggle.com/code/spidy20/3d-visualization-of-multiple-linear-regression/notebook\n",
        "  # https://gist.github.com/aricooperdavis/c658fc1c5d9bdc5b50ec94602328073b\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(111, projection='3d')\n",
        "  ax.set_xlabel(\"X1\")\n",
        "  ax.set_ylabel(\"X2\")\n",
        "  ax.set_zlabel(\"y\")\n",
        "  ax.scatter(x[:,0], x[:,1], y, marker='.', color='red')\n",
        "  \n",
        "  x1_min, x1_max = min(x[:,0]), max(x[:,0])\n",
        "  x2_min, x2_max = min(x[:,1]), max(x[:,1])\n",
        "  xs = scale(np.tile(np.arange(101), (101,1)), x1_min, x1_max)\n",
        "  ys = scale(np.tile(np.arange(101), (101,1)).T, x2_min, x2_max)\n",
        "  zs = beta[0] + xs*beta[1]+ ys*beta[2]\n",
        "  ax.plot_surface(xs,ys,zs, alpha=0.3)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def show(x, y, beta):\n",
        "  print(beta)\n",
        "\n",
        "  if len(beta) == 2:\n",
        "    plot2D(x, y, beta)\n",
        "  elif len(beta) == 3:\n",
        "    plot3D(x, y, beta)"
      ],
      "metadata": {
        "id": "ElI14AV4lrWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title randomLinearData() make_regression()\n",
        "# https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/validation_and_test_sets.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=validation_tf2-colab&hl=en\n",
        "import numpy as np\n",
        "\n",
        "def randomLinearData(beta, n):\n",
        "  np.random.seed(100) # seed random number generator\n",
        "  x = 1000 * np.random.rand(n)\n",
        "  e = 100 * np.random.rand(len(x))\n",
        "  y = beta[0] + x*beta[1] + e\n",
        "  return ([[e] for e in x], y)\n",
        "\n",
        "from sklearn import datasets\n",
        "def make_regression(n_samples, n_features, intercept=10):\n",
        "  return datasets.make_regression(n_samples=n_samples,#number of samples\n",
        "                                      n_features=n_features,#number of features\n",
        "                                      n_informative=n_features,#number of useful features \n",
        "                                      bias=intercept,\n",
        "                                      noise=10,#bias and standard deviation of the guassian noise\n",
        "                                      coef=True,#true coefficient used to generated the data\n",
        "                                      random_state=0) #set for same data points for each run"
      ],
      "metadata": {
        "id": "Kq-utI6FnaRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression:  OLS methods"
      ],
      "metadata": {
        "id": "N1POWN05MwW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **$\\hat{β}$** = (X<sup>T</sup>X)<sup>-1</sup> X<sup>T</sup>**y**. https://cmdlinetips.com/2020/03/linear-regression-using-matrix-multiplication-in-python-using-numpy/\n",
        "2. **$\\hat{β}$** = X<sup>pseudo-inverse</sup> **y**\n",
        "3. scipy.linalg.lstsq https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lstsq.html#scipy.linalg.lstsq\n",
        "4. sklearn LinearRegression https://cmdlinetips.com/2020/03/linear-regression-using-matrix-multiplication-in-python-using-numpy/\n"
      ],
      "metadata": {
        "id": "aHMpKpUc-k_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.linalg import lstsq\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "''' Create X_mat with first column as 1's from x'''\n",
        "def make_X_mat(x):\n",
        "  X_mat=np.vstack((np.ones(len(x)), np.array(x).T)).T\n",
        "  # print(X_mat)\n",
        "  return X_mat\n",
        "\n",
        "# 1. https://cmdlinetips.com/2020/03/linear-regression-using-matrix-multiplication-in-python-using-numpy/\n",
        "def ols_with_inverse(X_mat, y):\n",
        "  return np.linalg.inv(X_mat.T.dot(X_mat)).dot(X_mat.T).dot(y)\n",
        "\n",
        "# 2.\n",
        "def ols_with_pseudoinverse(X_mat, y):\n",
        "  return np.linalg.pinv(X_mat).dot(y)\n",
        "\n",
        "# 3. https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.lstsq.html#scipy.linalg.lstsq\n",
        "def ols_with_numpy_lstsq(X_mat, y):\n",
        "  beta_hat, res, rnk, s = lstsq(X_mat, y)\n",
        "  return beta_hat\n",
        "  \n",
        "# 4. sklearn.linear_model.LinearRegression https://cmdlinetips.com/2020/03/linear-regression-using-matrix-multiplication-in-python-using-numpy/\n",
        "def ols_with_sklearn(X_mat, y):\n",
        "  lr = LinearRegression().fit(x, y)\n",
        "  beta_hat = np.insert(lr.coef_, 0, lr.intercept_, axis=0)\n",
        "  return beta_hat\n",
        "\n",
        "def show_olss(x, y, inv=False, pinv=False, lstsq=False, sklearn=True):\n",
        "  X_mat=make_X_mat(x)\n",
        "  if inv:\n",
        "    show(x, y, ols_with_inverse(X_mat, y))\n",
        "  if pinv:\n",
        "    show(x, y, ols_with_pseudoinverse(X_mat, y))\n",
        "  if lstsq:\n",
        "    show(x, y, ols_with_numpy_lstsq(X_mat, y))\n",
        "  if sklearn:\n",
        "    show(x, y, ols_with_sklearn(X_mat, y))"
      ],
      "metadata": {
        "id": "0UBsSpChprbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x, y) = randomLinearData([50, 3], 100)\n",
        "show_olss(x, y, inv=True, pinv=True, lstsq=True, sklearn=True)"
      ],
      "metadata": {
        "id": "FomYIOMKVQJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y, coef = make_regression(n_samples=100, n_features=1)\n",
        "print(coef)\n",
        "show_olss(x, y)"
      ],
      "metadata": {
        "id": "NPKctrrvXYrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y, coef = make_regression(n_samples=1000, n_features=2, intercept=3)\n",
        "print(coef)\n",
        "show_olss(x, y)"
      ],
      "metadata": {
        "id": "E4X31-r9AKb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression: Gradient descent\n",
        "\n"
      ],
      "metadata": {
        "id": "mNDFctL4Mw52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/calculating-gradient-descent-manually-6d9bee09aa0b\n",
        "\n",
        "https://www.geeksforgeeks.org/ml-mini-batch-gradient-descent-with-python/\n",
        "\n",
        "https://towardsdatascience.com/linear-regression-using-gradient-descent-97a6c8700931\n",
        "\n"
      ],
      "metadata": {
        "id": "XYiWE3zpPD8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_gd(x, y):\n",
        "  show_olss(x, y)\n"
      ],
      "metadata": {
        "id": "wmUpjplo4mVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y, coef = make_regression(n_samples=1000, n_features=10)\n",
        "print(coef)\n",
        "show_gd(x, y)"
      ],
      "metadata": {
        "id": "Cq1UXYnv4YzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression; Gradient descent with automatic differentiation\n"
      ],
      "metadata": {
        "id": "pxtPugaq2dqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* https://mdrk.io/introduction-to-automatic-differentiation/\n"
      ],
      "metadata": {
        "id": "633cpyvn21mF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression: TensorFlow\n"
      ],
      "metadata": {
        "id": "mU7GRkOBMxGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "References\n",
        "\n",
        "* https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/validation_and_test_sets.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=validation_tf2-colab&hl=en#scrollTo=FBhNIdUatOU6\n",
        "\n",
        "* https://colab.research.google.com/github/kaustubholpadkar/Predicting-House-Price-using-Multivariate-Linear-Regression/blob/master/Multivariate_Linear_Regression_Python.ipynb\n",
        "\n",
        "* https://www.coursera.org/projects/regression-automatic-differentiation-tensorflow\n",
        "\n"
      ],
      "metadata": {
        "id": "RD7wkqxjTWOi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiywV4hNLpHc"
      },
      "outputs": [],
      "source": [
        "#@title Run on TensorFlow 2.x\n",
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format"
      ],
      "metadata": {
        "id": "QIwZH0faTdic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML"
      ],
      "metadata": {
        "id": "V1M3sCmG5tvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering\n",
        "\n",
        "* Load data\n",
        "* Shuffle\n",
        "* Split into training, validation and test. \n",
        "* Scale label column to meaningful values\n",
        "\n",
        "Features\n",
        "* Bucketize, cross \n",
        "* Scale features - min max or z scale\n",
        "\n",
        "\n",
        "References\n",
        "\n",
        "* https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/representation_with_a_feature_cross.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=representation_tf2-colab&hl=en\n"
      ],
      "metadata": {
        "id": "O-CT6ZDe5zLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define and Train Models\n",
        "* create model\n",
        "* train model\n",
        "* plot loss curves\n"
      ],
      "metadata": {
        "id": "Mup-lMKY59zw"
      }
    }
  ]
}