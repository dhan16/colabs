{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WikiData.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhan16/colabs/blob/master/covid19opendata/WikiData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBPE7RREhexA"
      },
      "source": [
        "## WikiData"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsXCiAFtToqX"
      },
      "source": [
        "# Sparql functions\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "ENDPOINT = \"https://query.wikidata.org/sparql\"\n",
        "\n",
        "\n",
        "def wiki_data(sparql):\n",
        "  res = requests.get(ENDPOINT, params = {'format': 'json', 'query': sparql})\n",
        "  return res.json()\n",
        "\n",
        "\n",
        "def wikidata_to_dataframe(json):\n",
        "  results = json[\"results\"][\"bindings\"]\n",
        "  # column names we draw from the first result\n",
        "  cols = [ val for val in results[0] ]\n",
        "  rows = []\n",
        "  for result in results:\n",
        "      values = [ result[val][\"value\"] for val in result ]\n",
        "      rows.append(values)\n",
        "  return pd.DataFrame(rows, columns=cols)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peZ8W9AXTsgS"
      },
      "source": [
        "sparql = \"\"\"\n",
        "SELECT ?place ?placeLabel ?class ?classLabel\n",
        "WHERE\n",
        "{\n",
        "  ?place wdt:P31/wdt:P279* wd:Q12479774.\n",
        "  ?place wdt:P31 ?class.\n",
        "  ?class wdt:P279 wd:Q12479774.\n",
        "  SERVICE wikibase:label {\n",
        "    bd:serviceParam wikibase:language \"en\" .\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "res = wiki_data(sparql)\n",
        "wiki_raw = wikidata_to_dataframe(res)\n",
        "wiki_raw\n",
        "# res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrj9TYOMjC-2"
      },
      "source": [
        "wiki_df = wiki_raw.copy()\n",
        "\n",
        "# wiki_raw.classLabel.unique()\n",
        "kabkota_to_regiontype = {\n",
        "    'regency of Indonesia' : 'Regency',\n",
        "    'administrative regency of Indonesia' : 'Regency',\n",
        "    'city of Indonesia': 'City',\n",
        "    'administrative city of Indonesia': 'City',\n",
        "}\n",
        "wiki_df['regiontype'] = wiki_df.apply(lambda r: kabkota_to_regiontype[r.classLabel], axis=1)\n",
        "wiki_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKafJnbWhj4N"
      },
      "source": [
        "## Sheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY-at9fDvEw2"
      },
      "source": [
        "!pip install --upgrade gspread"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FfHayj5wQFf"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "sheet_url = 'https://docs.google.com/spreadsheets/d/1FJJXiGuOb5nXrjJeV3QcHNhTo38YdcsTIFl29mWDIqI/edit#gid=2006070746'\n",
        "worksheet = gc.open_by_url(sheet_url).worksheet('Kode Kota')\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "sheet_raw = pd.DataFrame.from_records(rows[2:], columns=rows[1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADqs-dvZbKcK"
      },
      "source": [
        "sheet_df = sheet_raw.copy()\n",
        "\n",
        "kabkota_to_regiontype = {\n",
        "    'Kab.' : 'Regency', \n",
        "    'Kota': 'City', \n",
        "    'zTam' : 'zTam'\n",
        "}\n",
        "sheet_df['regiontype'] = sheet_df.apply(lambda r: kabkota_to_regiontype[r.KabKota], axis=1)\n",
        "sheet_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFlIhVuxhoSw"
      },
      "source": [
        "## Sheet vs WikiData"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA0n3hB_sJod"
      },
      "source": [
        "def indonesian_direction_to_english(place: str):\n",
        "  # place is in lower\n",
        "  to_english = {\n",
        "      'pusat': 'central',\n",
        "      'tengah' : 'central',\n",
        "      'utara' : 'north',\n",
        "      'selatan' : 'south',\n",
        "      'timur' : 'east',\n",
        "      'barat' : 'west',\n",
        "  }\n",
        "  bits = place.split()\n",
        "  if len(bits) > 1:\n",
        "    for indo_dir, eng_dir in to_english.items():\n",
        "      # in indonesian the dir is at the end. island/islands \n",
        "      if bits[-1] == indo_dir:\n",
        "        bits.pop()\n",
        "        bits.insert(0, eng_dir)\n",
        "        break\n",
        "  place = ' '.join(bits)\n",
        "  return place\n",
        "\n",
        "def indonesian_to_english(place: str):\n",
        "  # place is in lower\n",
        "  to_english = {\n",
        "      'kepulauan' : 'islands',\n",
        "      'pulau' : 'island',\n",
        "  }\n",
        "  bits = place.split()\n",
        "  if len(bits) > 1:\n",
        "    for indo, eng in to_english.items():\n",
        "      # in indonesian the island is at the beginning while in english its at the end\n",
        "      if bits[0] == indo:\n",
        "        bits.pop(0)\n",
        "        bits.append(eng)\n",
        "        break\n",
        "  place = ' '.join(bits)\n",
        "  return place\n",
        "\n",
        "# indonesian_direction_to_english('tengah whatever')\n",
        "indonesian_direction_to_english('whatever tengah')\n",
        "indonesian_to_english('kepulauan tengah')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuGOXheJonAl"
      },
      "source": [
        "spellings = {\n",
        "    'Toba Samosir' : 'Toba Regency',\n",
        "    'Penajam Paser Utara' : 'Penajam North Paser',\n",
        "    'Kupang' : 'Kupang Regency',\n",
        "    'Kepulauan Seribu' : 'Thousand Islands',\n",
        "    'Pangkajene Kepulauan' : 'Pangkajene Islands',\n",
        "    'Pasangkayu (Mamuju Utara)': 'Pasangkayu', # https://en.wikipedia.org/wiki/Pasangkayu_Regency\n",
        "    # due to dashes\n",
        "    'Bau-Bau' : 'Baubau',\n",
        "    'Tojo Una-Una' : 'Tojo Una Una',\n",
        "    'Toli-Toli': 'Tolitoli',\n",
        "     # verify below\n",
        "    'Kepulauan Sangihe' : 'Sangihe',\n",
        "    'Kepulauan Sitaro' : 'Kepulauan Siau Tagulandang Biaro',\n",
        "}\n",
        "def standard_place_spelling(place: str):\n",
        "   # other spellings if still required\n",
        "  place = spellings.get(place, place)\n",
        "  # all lowercase\n",
        "  place = place.lower()\n",
        "  # apply translations\n",
        "  place = indonesian_direction_to_english(place)\n",
        "  place = indonesian_to_english(place)\n",
        "  # remove spaces\n",
        "  place = place.replace(' ', '')\n",
        "  return place\n",
        "\n",
        "\n",
        "wiki_df['place_standardised'] = wiki_df.apply(lambda r: standard_place_spelling(r.placeLabel), axis=1)\n",
        "sheet_df['Kota_standardised'] = sheet_df.apply(lambda r: standard_place_spelling(r.Kota), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgHa2Y63jMrE"
      },
      "source": [
        "# Find rows in wiki_df with no matches in sheet_df\n",
        "df = wiki_df.merge(sheet_df, how='left', right_on=['Kota_standardised', 'regiontype'], left_on=['place_standardised', 'regiontype']) \n",
        "missing = df[df['Kota'].isnull()]\n",
        "missing\n",
        "# len(missing)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3093cpm0nRU"
      },
      "source": [
        "# Find rows in sheet_df with no matches in wiki_df\n",
        "df = sheet_df.merge(wiki_df, how='left', left_on=['Kota_standardised', 'regiontype'], right_on=['place_standardised', 'regiontype']) \n",
        "# missing = df[df['placeLabel'].isnull() & ~df['KabKota'].isin(['zTam'])]\n",
        "missing = df[df['placeLabel'].isnull()]\n",
        "missing\n",
        "# len(missing)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}